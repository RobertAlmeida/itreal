# ğŸ§  Guia Completo de Treinamento do Modelo

Este guia detalha todo o processo de treinamento do modelo de detecÃ§Ã£o de IA, desde a preparaÃ§Ã£o dos dados atÃ© a avaliaÃ§Ã£o final.

---

## ğŸ“‹ Ãndice

1. [PrÃ©-requisitos](#prÃ©-requisitos)
2. [PreparaÃ§Ã£o do Dataset](#preparaÃ§Ã£o-do-dataset)
3. [ConfiguraÃ§Ã£o do Ambiente](#configuraÃ§Ã£o-do-ambiente)
4. [ExecuÃ§Ã£o do Treinamento](#execuÃ§Ã£o-do-treinamento)
5. [Monitoramento](#monitoramento)
6. [AvaliaÃ§Ã£o do Modelo](#avaliaÃ§Ã£o-do-modelo)
7. [Troubleshooting](#troubleshooting)

---

## ğŸ”§ PrÃ©-requisitos

### Hardware Recomendado

- **GPU**: NVIDIA com CUDA (recomendado)
  - MÃ­nimo: 6GB VRAM (GTX 1060, RTX 2060)
  - Recomendado: 8GB+ VRAM (RTX 3060, RTX 3070)
- **RAM**: 16GB mÃ­nimo, 32GB recomendado
- **Armazenamento**: 20GB+ livres

### Software

- Python 3.8+
- CUDA 11.8+ (se usar GPU)
- Git

### Verificar GPU (Opcional)

```bash
# Verificar se CUDA estÃ¡ disponÃ­vel
python -c "import torch; print(f'CUDA disponÃ­vel: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"
```

**SaÃ­da esperada com GPU**:
```
CUDA disponÃ­vel: True
GPU: NVIDIA GeForce RTX 3060
```

**SaÃ­da esperada sem GPU**:
```
CUDA disponÃ­vel: False
GPU: N/A
```

> âš ï¸ **Nota**: O treinamento funciona em CPU, mas serÃ¡ **muito mais lento** (10-20x).

---

## ğŸ“ PreparaÃ§Ã£o do Dataset

### Estrutura de DiretÃ³rios

O dataset deve estar organizado assim:

```
dataset/
â”œâ”€â”€ ai/          # Imagens geradas por IA
â”‚   â”œâ”€â”€ img001.jpg
â”‚   â”œâ”€â”€ img002.png
â”‚   â””â”€â”€ ...
â””â”€â”€ real/        # Imagens reais/naturais
    â”œâ”€â”€ img001.jpg
    â”œâ”€â”€ img002.png
    â””â”€â”€ ...
```

### Passo 1: Criar Estrutura

```bash
# Criar diretÃ³rios
mkdir -p dataset/ai
mkdir -p dataset/real
```

### Passo 2: Coletar Imagens

#### Imagens de IA (Classe `ai/`)

Fontes sugeridas:
- **Midjourney**: Imagens do Discord
- **DALL-E**: OpenAI
- **Stable Diffusion**: Geradores locais
- **Artbreeder**: Portraits gerados
- **ThisPersonDoesNotExist**: Rostos sintÃ©ticos

```bash
# Exemplo: baixar imagens de IA
cd dataset/ai/

# Adicione suas imagens aqui
# Formatos suportados: JPG, PNG, WEBP
```

#### Imagens Reais (Classe `real/`)

Fontes sugeridas:
- **Flickr**: Fotos reais com licenÃ§a
- **Unsplash**: Fotos de alta qualidade
- **COCO Dataset**: Dataset pÃºblico
- **ImageNet**: Subconjuntos
- **Suas prÃ³prias fotos**: CÃ¢mera/celular

```bash
# Exemplo: baixar imagens reais
cd dataset/real/

# Adicione suas imagens aqui
```

### Passo 3: Validar Dataset

```bash
# Contar imagens
echo "Imagens de IA: $(ls dataset/ai/ | wc -l)"
echo "Imagens reais: $(ls dataset/real/ | wc -l)"
```

**RecomendaÃ§Ãµes**:
- âœ… **MÃ­nimo**: 500 imagens por classe (1000 total)
- âœ… **Bom**: 1000-2000 imagens por classe
- âœ… **Ã“timo**: 5000+ imagens por classe
- âœ… **Balanceamento**: NÃºmero similar em ambas as classes

### Passo 4: Verificar Qualidade

```python
# Script para verificar imagens corrompidas
from PIL import Image
import os

def check_images(directory):
    corrupted = []
    for filename in os.listdir(directory):
        filepath = os.path.join(directory, filename)
        try:
            img = Image.open(filepath)
            img.verify()
        except Exception as e:
            corrupted.append(filepath)
            print(f"âŒ Corrompida: {filepath}")
    
    print(f"\nâœ… Total verificadas: {len(os.listdir(directory))}")
    print(f"âŒ Corrompidas: {len(corrupted)}")
    return corrupted

# Verificar
print("Verificando imagens de IA...")
check_images("dataset/ai")

print("\nVerificando imagens reais...")
check_images("dataset/real")
```

---

## âš™ï¸ ConfiguraÃ§Ã£o do Ambiente

### Passo 1: Criar Ambiente Virtual

```bash
# Criar venv
python -m venv venv

# Ativar
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
```

### Passo 2: Instalar DependÃªncias

```bash
# Atualizar pip
pip install --upgrade pip

# Instalar dependÃªncias
pip install -r requirements.txt
```

**Tempo estimado**: 5-10 minutos

### Passo 3: Configurar ParÃ¢metros de Treinamento

Edite `train_model.py` se necessÃ¡rio:

```python
class TrainingConfig:
    # Dados
    dataset_path = "./dataset"
    val_ratio = 0.2              # 20% para validaÃ§Ã£o
    batch_size = 32              # Reduzir se pouca VRAM
    
    # Treinamento
    epochs = 150                 # MÃ¡ximo de epochs
    learning_rate = 1e-5         # Taxa de aprendizado
    
    # Early Stopping
    early_stopping_patience = 15 # Parar apÃ³s 15 epochs sem melhora
    
    # Mixed Precision
    use_amp = True               # Usar AMP (mais rÃ¡pido)
    
    # Device
    device = "cuda"              # "cuda" ou "cpu"
```

**Ajustes comuns**:

| SituaÃ§Ã£o | Ajuste |
|----------|--------|
| Pouca VRAM (4-6GB) | `batch_size = 16` |
| Muito pouca VRAM (<4GB) | `batch_size = 8`, `use_amp = False` |
| CPU apenas | `device = "cpu"`, `batch_size = 16` |
| Dataset pequeno (<1000) | `epochs = 100`, `early_stopping_patience = 10` |

---

## ğŸš€ ExecuÃ§Ã£o do Treinamento

### Passo 1: Iniciar Treinamento

```bash
# Executar script
python train_model.py
```

### Passo 2: Entender a SaÃ­da

**InÃ­cio do treinamento**:
```
Loading dataset...
Total images: 2000
Classes: ['ai', 'real']
Training images: 1600
Validation images: 400

Initializing efficientnet_b0...
Model loaded on cuda

==================================================
STARTING TRAINING
==================================================
```

**Durante cada epoch**:
```
Epoch 1/150
--------------------------------------------------
  Batch [10/50] Loss: 0.6234 Acc: 0.6250
  Batch [20/50] Loss: 0.5891 Acc: 0.6875
  ...

  Train Loss: 0.5234 | Train Acc: 0.7125
  Val Loss:   0.4891 | Val Acc:   0.7625
  Learning Rate: 1.00e-05
  
âœ“ Best checkpoint saved! Val Loss: 0.4891
```

**MÃ©tricas importantes**:
- `Train Loss`: Menor Ã© melhor (objetivo: <0.3)
- `Train Acc`: Maior Ã© melhor (objetivo: >0.90)
- `Val Loss`: Menor Ã© melhor (objetivo: <0.4)
- `Val Acc`: Maior Ã© melhor (objetivo: >0.85)

### Passo 3: Early Stopping

Se o modelo parar de melhorar:

```
EarlyStopping counter: 1/15
EarlyStopping counter: 2/15
...
EarlyStopping counter: 15/15

âš ï¸  Early stopping triggered at epoch 45
```

Isso Ã© **normal** e **desejÃ¡vel** - previne overfitting!

### Passo 4: ConclusÃ£o

```
==================================================
TRAINING COMPLETED
==================================================

âœ“ Final model saved to: app/models/ai_detector_model.pth
âœ“ Training history saved to: checkpoints/training_history.json

Best Validation Accuracy: 0.8750
Best Validation Loss: 0.3245
Total Epochs Trained: 45

âœ“ Training complete!
```

**Tempo estimado**:
- **GPU (RTX 3060)**: 30-60 minutos
- **GPU (GTX 1060)**: 1-2 horas
- **CPU**: 8-12 horas

---

## ğŸ“Š Monitoramento

### OpÃ§Ã£o 1: TensorBoard (Recomendado)

**Terminal 1** (Treinamento):
```bash
python train_model.py
```

**Terminal 2** (TensorBoard):
```bash
# Iniciar TensorBoard
tensorboard --logdir=runs

# Acesse: http://localhost:6006
```

**GrÃ¡ficos disponÃ­veis**:
- ğŸ“‰ Loss/train - Perda no treino
- ğŸ“‰ Loss/val - Perda na validaÃ§Ã£o
- ğŸ“ˆ Accuracy/train - AcurÃ¡cia no treino
- ğŸ“ˆ Accuracy/val - AcurÃ¡cia na validaÃ§Ã£o
- ğŸ“Š Learning_Rate - Taxa de aprendizado

**O que observar**:
- âœ… **Bom**: Val loss diminuindo, val acc aumentando
- âš ï¸ **Overfitting**: Train acc >> Val acc (diferenÃ§a >10%)
- âŒ **Underfitting**: Ambas as acurÃ¡cias baixas (<70%)

### OpÃ§Ã£o 2: Logs em Tempo Real

```bash
# Em outro terminal
tail -f logs/app.log
```

### OpÃ§Ã£o 3: HistÃ³rico JSON

ApÃ³s o treinamento:

```bash
# Ver histÃ³rico
cat checkpoints/training_history.json | jq
```

---

## ğŸ¯ AvaliaÃ§Ã£o do Modelo

### Verificar Checkpoints

```bash
# Listar checkpoints salvos
ls -lh checkpoints/

# SaÃ­da esperada:
# best_checkpoint.pth      - Melhor modelo
# last_checkpoint.pth      - Ãšltimo epoch
# training_history.json    - HistÃ³rico completo
```

### Testar Modelo

```bash
# Iniciar API
uvicorn app.main:app --reload

# Em outro terminal, testar com imagem
curl -X POST "http://localhost:8000/detect/image" \
  -F "file=@test_image.jpg"
```

**Resposta esperada**:
```json
{
  "type": "image",
  "filename": "test_image.jpg",
  "ai_probability": {
    "ai_probability": 0.8234,
    "real_probability": 0.1766,
    "predicted": "IA"
  },
  "metadata_suspicious": true,
  "exif": {...}
}
```

### MÃ©tricas de Qualidade

**Excelente modelo**:
- âœ… Val Accuracy > 90%
- âœ… Val Loss < 0.3
- âœ… DiferenÃ§a Train/Val Acc < 5%

**Bom modelo**:
- âœ… Val Accuracy > 85%
- âœ… Val Loss < 0.4
- âœ… DiferenÃ§a Train/Val Acc < 10%

**Modelo aceitÃ¡vel**:
- âš ï¸ Val Accuracy > 75%
- âš ï¸ Val Loss < 0.5
- âš ï¸ DiferenÃ§a Train/Val Acc < 15%

**Modelo ruim** (retreinar):
- âŒ Val Accuracy < 75%
- âŒ Val Loss > 0.5
- âŒ DiferenÃ§a Train/Val Acc > 15%

---

## ğŸ” Troubleshooting

### Erro: CUDA out of memory

**Sintoma**:
```
RuntimeError: CUDA out of memory
```

**SoluÃ§Ã£o**:
```python
# Editar train_model.py
class TrainingConfig:
    batch_size = 16  # ou 8
    use_amp = True   # Certifique-se que estÃ¡ True
```

### Erro: Dataset vazio

**Sintoma**:
```
RuntimeError: Found 0 files in subfolders of: ./dataset
```

**SoluÃ§Ã£o**:
```bash
# Verificar estrutura
ls -R dataset/

# Deve ter:
# dataset/ai/
# dataset/real/
```

### Overfitting (Train Acc >> Val Acc)

**Sintoma**:
- Train Acc: 95%
- Val Acc: 70%

**SoluÃ§Ãµes**:
1. **Mais dados**: Adicionar mais imagens
2. **Mais augmentation**: Editar `train_transform`
3. **Early stopping**: JÃ¡ implementado
4. **RegularizaÃ§Ã£o**: Aumentar `weight_decay`

```python
class TrainingConfig:
    weight_decay = 1e-3  # Aumentar de 1e-4
```

### Underfitting (Ambas acurÃ¡cias baixas)

**Sintoma**:
- Train Acc: 65%
- Val Acc: 63%

**SoluÃ§Ãµes**:
1. **Mais epochs**: Aumentar `epochs`
2. **Learning rate**: Aumentar para `1e-4`
3. **Modelo maior**: Usar `efficientnet_b1` ou `b2`

### Treinamento muito lento

**CPU**:
```python
# Reduzir batch size
batch_size = 8
num_workers = 2
```

**GPU antiga**:
```python
# Desabilitar AMP
use_amp = False
batch_size = 16
```

### Modelo nÃ£o melhora

**Sintoma**:
- Val Loss estagnado em ~0.69 (50% accuracy)

**Causas possÃ­veis**:
1. **Dataset ruim**: Imagens muito similares
2. **Learning rate alto**: Reduzir para `1e-6`
3. **Modelo congelado**: Verificar `requires_grad=True`

---

## ğŸ“ˆ Melhorando o Modelo

### 1. Aumentar Dataset

Mais dados = melhor modelo!

**Objetivo**: 5000+ imagens por classe

### 2. Data Augmentation Customizada

Editar `train_transform` em `train_model.py`:

```python
train_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(20),  # Aumentar rotaÃ§Ã£o
    transforms.RandomResizedCrop(256, scale=(0.6, 1.0)),  # Mais crop
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.15),
    transforms.RandomGrayscale(p=0.15),
    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),  # Adicionar blur
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
```

### 3. Experimentar Modelos Maiores

```python
# Em train_model.py
model = models.efficientnet_b1(pretrained=True)  # ou b2, b3
```

**Trade-off**:
- âœ… Maior acurÃ¡cia
- âŒ Mais lento
- âŒ Mais VRAM

### 4. Learning Rate Finder

```python
# Testar diferentes learning rates
learning_rates = [1e-6, 5e-6, 1e-5, 5e-5, 1e-4]

# Treinar por 5 epochs cada e comparar
```

---

## âœ… Checklist Final

Antes de usar o modelo em produÃ§Ã£o:

- [ ] Val Accuracy > 85%
- [ ] Val Loss < 0.4
- [ ] Testado com imagens reais
- [ ] Testado com imagens de IA
- [ ] Sem overfitting (Train/Val diff < 10%)
- [ ] Checkpoints salvos
- [ ] HistÃ³rico de treinamento documentado
- [ ] TensorBoard logs revisados

---

## ğŸ“š Recursos Adicionais

### Datasets PÃºblicos

- **CIFAKE**: https://www.kaggle.com/datasets/birdy654/cifake-real-and-ai-generated-synthetic-images
- **AI vs Real**: https://www.kaggle.com/datasets/superpotato9/dalle-recognition-dataset
- **Synthetic Faces**: https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces

### Ferramentas

- **TensorBoard**: VisualizaÃ§Ã£o de mÃ©tricas
- **Weights & Biases**: Tracking de experimentos
- **MLflow**: Gerenciamento de modelos

### Leitura Recomendada

- [EfficientNet Paper](https://arxiv.org/abs/1905.11946)
- [Transfer Learning Guide](https://cs231n.github.io/transfer-learning/)
- [Data Augmentation Techniques](https://pytorch.org/vision/stable/transforms.html)

---

## ğŸ“ PrÃ³ximos Passos

ApÃ³s treinar o modelo com sucesso:

1. **Deploy**: Usar Docker para produÃ§Ã£o
2. **Monitoramento**: Configurar logs e mÃ©tricas
3. **A/B Testing**: Comparar versÃµes do modelo
4. **Retreinamento**: Atualizar com novos dados periodicamente

---

**Boa sorte com o treinamento! ğŸš€**

Se tiver dÃºvidas, consulte o [README](README.md) ou abra uma issue no GitHub.
